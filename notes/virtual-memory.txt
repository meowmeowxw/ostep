--------------------------------------------------------------------------------
Address Space
--------------------------------------------------------------------------------

In a modern os there are multiple processes running on the system. Using
scheduling policy we can virtualize the cpu, however we need to virtualize
memory too.

Why?

For example we wants to implement protections, you don't want a process to be 
read, or worse, write some other process's memory. Another feature was the
interactivity, if you don't virtualize memory then every time the os issue a 
context switch, then the os need to save all the information of a process in a
physical memory and then run the other process. This process is very slow, so
we need to find solutions to this problem.

The abstraction of physical memory is called address space, and it is the
running program's view of memory in the system.

Example:

0KB     -------------------
            Program Code
1KB     -------------------
            Heap
2KB     -------------------
                |
                v

            Free

                ^
                |
15KB    -------------------
            Stack
16KB    -------------------

In this case the stack and heap of a program can shrink at runtime, and the
process in not loaded in physical memory 0->16KB since those addresses are
virtualized.

The goal of a virtual memory (VM) system are:

1. Transparency, the os should implement virtual memory in a way that is
   invisible to the running program.
2. Efficieny both in time and space.
3. Protection.

--------------------------------------------------------------------------------
Memory API
--------------------------------------------------------------------------------

In running a C program, there are two types of memory that are allocated. The
first is called stack memory, and allocations and deallocations of it are
managed implicitly by the compiler for you. The stack is also called automatic
memory.

Example of code:

#include <stdio.h>
#include <string.h>

void print(char *src) {
    char dst[64];
    strcpy(dst, src);
    printf("dst: %s\n", dst);
}

int main(int argc, char **argv) {
    char src[] = "hi ostep readers!";
    print(src);
	return 0;
}

disassembly of print:

opcodes         instructions

55             push rbp
4889e5         mov rbp, rsp
4883ec50       sub rsp, 0x50
48897db8       mov qword [src], rdi        ; arg1
488b55b8       mov rdx, qword [src]
488d45c0       lea rax, [dest]
4889d6         mov rsi, rdx                ; const char *src
4889c7         mov rdi, rax                ; char *dst
e8c8feffff     call sym.imp.strcpy         ;
488d45c0       lea rax, [dest]
4889c6         mov rsi, rax
488d3d8e0e00   lea rdi, str.dst
b800000000     mov eax, 0
e8c0feffff     call sym.imp.printf
90             nop
c9             leave
c3             ret

With the instructions push and pop we insert and extract instructions to/from
the stack. 
With the first three isntruction we push the precedent base pointer of the main 
function, and we "allocate" on the stack 0x50 bytes of space, so the compiler
has increased the dimension of the stack to contain our *dst.
At the end of the function the program issue a leave instruction which moves
the stack pointer to the current base pointer and then it pop the base pointer.
The last instruction is ret which pop from the stack the return address and 
set the instruction pointer to it.

Another type of memory is the heap which is created dynamically using the malloc
instruction.

int *x = (int *)malloc(sizeof(int));

With this instruction we allocate on the heap the size of an int (usually 4B).
When we don't need that space anymore we can free the space on the heap using
free:

free(x);

There are lots of bug around the heap, for example is always good practice to 
check the return value of the malloc, if the dimension requested is too large
the malloc returns NULL. Another good practice is to never reuse a variable
after it has been freed (UAF - Use After Free bugs), or never free twice the
same pointer (Double Free).

To detect potential bugs we can use a tool called valgrind.

Notes that we didn't use syscalls, but library function. At the base of the
malloc there are two syscall:

1. brk/sbrk which increase/decrease the size of the heap.
2. mmap which can create an anonymous memory region (memory not associated with
   any particular file) and that can be treated like a heap.

Never use these two syscalls to manage the heap or the program will crash
with the probability of 99.99%.

--------------------------------------------------------------------------------
Address Translation
--------------------------------------------------------------------------------

The generic technique we will use is something that is referred to as 
hardware-based address translation, or just address translation for short. With
address translation the hardware converts each memmory access changing the
virtual address provided by the instruction to a physical address where the 
desired information is actually located.

Of course, the hardware alone cannot virtualize memory, as it just provides the
low-level mechanism for doing so efficiently. The OS must get involved at key
points to set up the hardware so that the correct translations take place; it
must thus manage memory, keeping track of which locations are free and which are
in use, and judiciously intervening to maintain control over how memory is used.

As scheduling policy we need to do some assumptions to get to a final solution.
The first one is that the user's address space must be placed contiguosly in
physical memory, and that the size of the address space is less than the 
physical memory. Another assumption is that each address space is exactly the
same size.

Process 1 address space:

0KB     -------------------
            Program Code
1KB     -------------------
            Heap
2KB     -------------------
                |
                v

            Free

                ^
                |
15KB    -------------------
            Stack
16KB    -------------------


From the process perspective its address space start at 0KB and end at 16KB,
however the os wants to place the process somewhere else in physical memory not
necessarily at address 0. Example:

Physical memory:

0KB     ------------------
            OS
16KB    ------------------
            Not in Use
32KB    ------------------
            Process 1
48KB    ------------------
            Not in Use
64KB    ------------------

Thus, we want to relocate this process in memory in a way that is transparent
to the process itself.

The first idea introduced on the 1950's is referred as base and bounds, also
called dynamic relocation. Specifically we need two hardware register within
each CPU: one is called base register and the other the bounds/limit. In this
way the program is compiled as if it is loaded at address 0. However, when a 
program starts running, the os decides where in physical memory it should be
loaded and sets the base register to that value. In the above example the os
decides that the process must be relocated to address 32KB and set the base
register = 32KB. Now any memory reference is translated by the processor in the
following manner:

physical address = virtual address + base

If we have an instruction at address 300 like:

300: mov [ebx], eax

The instruction pointer (ip) or program counter (pc) is set to 300 and when
the hardware needs to fetch this instruction, it first add the value to the base
register and obtains the physical address 32KB + 300.
Before fetching the instruction the CPU will check if the memory reference is
within bounds to make sure it is legal (protection), if it's greater than the 
bounds the cpu raise an exception. The base and bounds registers are hardware
structures kept on the chip, and the process that helps the processor with 
address translation is called Memory Management Unit (MMU).

The hardware should provide special privileged (kernel) instruction to change
the base and bound registers, allowing the OS to change them when different
processes run. The os must manage the free space using some kind of data
structures (ex. free list), and when a process terminates update the data
structure. The os must save and restore the base and bounds register in for each
process (for context switch) and uses a structure called Process Control Block
(PCB). A last thing the os must handle the exception generated by the cpu,
usually it kills the process that has tried to access an invalid memory region.

--------------------------------------------------------------------------------
Segmentation
--------------------------------------------------------------------------------

Problem: there are lots of free space inside an address space of a process, for
example all the heap/stack unused.

The address space is divded between three logically-different segments: code,
stack, and heap. We can use a base and bounds pair per segment, to place each
segment indipendently in physical memory, example:

0KB     |-----------------|

        |    OS

16KB    |-----------------|
        |    Not in Use
26KB    |-----------------|
        |    Stack
28KB    |-----------------|
        |    Not in Use
32KB    |-----------------|
        |    Code
34KB    |-----------------|
        |    Heap
37KB    |-----------------|

        |    Not in Use

64KB    |-----------------|

Process address space:

0KB     |------------------|
        |    Program Code
2KB     |------------------|
        |    Unused
4KB     |------------------|
        |    Heap
7KB     |------------------|
        |        |
        |        v

        |    Free

        |        ^
        |        |
14KB    |------------------|
        |    Stack
16KB    |------------------|

Table:

Segment     Base    Size
-------------------------
Code        32K     2K
Heap        34K     3K
Stack       28K     2K

Let's suppose that we want to fetch some memory from the virtual address 4200
(heap). First we subtract from 4200 the virtual base address of the heap (4096),
so 4200-4096=104. Then we add to 104 the physical base register physical address
of the heap (34K) and we obtain the real physical address = 34920.

If we tried to refer to an illegal address as 11KB, the hardware detects that
the address is out of bounds, traps into the os, and kill the process.
SEGMENTATION FAULT ERROR.

How the hardware knows which pair of segment/offset to use to translate an
address? The technique used in the VAX/VMS system is an explicit approach, It's
uses the top bits of a virtual address to select which segments to translate.
Since we have three segments we need the top two bit.

00 -> Code
01 -> Heap
10 -> Stack
11 -> Stack

Example, if we have a 14bit virtual address, and as before we want to read the
virtual address 4200.

01          000001101000
segment     offset

01 is the heap segment and 000001101000 is the offset = 104, thus the hardware
simply takes the first two bits to determine which segment register to use and
the next 12 bits to as the offset into the segment.

Simple code:

SEG_MASK = 0x3000 = 0b11000000000000
SEG_SHIFT = 12
OFFSET_MASK = 0xfff = 0b00111111111111
Segment = (VirtualAddress & SEG_MASK) >> SEG_SHIFT
Offset = VirtualAddress & OFFSET_MASK
if (Offset >= Bounds[Segment])
    RaiseException(PROTECTION_FAULT)
else
    PhysAddr = Base[Segment] + Offset
    Register = AccessMemory(PhysAddr)

Most system to increase the address space only use one bit to decide which
segment to use and merge the heap with the code. Other systems use an implicit
approach, if an address is generated with the program counter is on the code
segment, if the address is based off of the stack/base pointer it must be on
the stack, otherwise on the heap.

The stack grows backwards (towords lower addresses), so in physical memory
it starts at 28K and grows back to 26K, while in virtual memory from 16K to 14K.
So the hardware must know which way the segment grows (a bit set to 1 if it
grows in positive direction and 0 if it grows in negative direction).

Virtual address 15KB should map to 27K in physical memory. In bit the address is
represented as: 11 1100 0000 0000. 11 designate the segment stack, and we have
an offset of 0xc00 = 3072 = 3K. In this case we substract from it the maximum
size of a segment = 4K, 3K - 4K = -1K. The base is 28K, and the physical address
is 28K - 1K = 27K.

Another important feature is the technique of code sharing to share certain
memory segments between address space. To do that the hardware needs an extra
support in the form of protections bits, for example the code segment can be
readable and executable, but not writable, while the stack can be readable and
writable.

With segmentation however we have a new problem, the size of a segment can
change (ex. using sbrk), and then the physical memory will become full of little
holes of free space, making it difficult to allocate new segments or to grow
existing ones. We call this problem external fragmentation. There are lots of 
algorithms to handle this problem like the best-fit, worst-fit, first-fit and
more complex like buddy algorithm, however no perfect solution exists for this
problem.

--------------------------------------------------------------------------------
Free-Space Management
--------------------------------------------------------------------------------

This is very hard to summarize so I will only list the characteristic of some
algorithms.
Free-Space Management is required when we have a problem of external
fragmentation, it could be the case with segmentation or the heap. In the latest
case the heap is managed by the pair of functions malloc/free.

There are several approach to manage the free space, the easiest is to use a
free list:

head -> 10 -> 30 -> 20 -> NULL

In the above example the list contains 3 free chunks, of size 10, 30, 20.

The most used algorithms on the free list are the following:

1. Best-fit: search through the free list and find chunks of free memory that
   are as big or bigger than the requested size. Then, return the one that is
   the smallest in that group of candidates;
2. Worst-fit: is the opposite of the best-fit, the scope is to leave big chunks
   free instead of losts of small chunks.
3. First-fit: simply finds the first block that is big enough and returns the
   requested amount to the user.
4. Next-fit: keep an extra pointer to the location within the list where one was
   looking last. The idea is to spread the search across all the free-list.

A more advanced method is the use of segregated list. If a particular
application has one (or a few) popular-sized request that it makes, keep a
separate list just to manage objects of that size; all other requests are
forwarded to a more general memory allocator. This is the case for the 
implementation of the glibc malloc, which uses fastbins to manage chunks with
popular size.

Link: https://sploitfun.wordpress.com/2015/02/10/understanding-glibc-malloc/

Another method is tu use a buddy allocation, the base of this allocator is to
recursively using a binary tree find enough space for the chunks requested.

--------------------------------------------------------------------------------
Paging
--------------------------------------------------------------------------------

The first approach was to choup things up into variable-sized pieces
(segmentation), thus it may be worth to consider a second approach: to chup up
space into fixed-sized pieces. We call this idea paging. We divide the address
space of a program into fixed-sized units, each of which we call a page. We view
physical memory as an array of fixed-sized slots called page frames; each of
these frames can contain a single virtual-memory page.

Example address space:

0   ---------------
        Page 0
16  ---------------
        Page 1
32  ---------------
        Page 2
48  ---------------
        Page 3
64  ---------------

Example 64 byte address space in a 128 byte physical memory:

0   -------------------
        OS
16  -------------------
        Unused
32  -------------------
        Page 3 of AS
48  -------------------
        Page 4 of AS
64  -------------------
        Unused
80  -------------------
        Page 2 of AS
96  -------------------
        Unused
112 -------------------
        Page 1 of AS
128 -------------------

In the above examples a page is 16B large and the OS can manage the free space
using a free list. To record where each virtual page of the address space is
placed in physical memory, the operating system usually keeps a per-process data
structure known as a page table. The major role of the page table is to store
address translations for each of the virtual pages of the address space, thus
letting us know where in physical memory each page resides.

Let's do an address translation of a virtual address. To translate the address
we need to split it into two components: the virtual page number (VPN) and the 
offset within the page. Because the virtual address space of the process is 64
bytes, we need 6 bits total for our virtual address (2^6 = 64). Thus our VA can
be conceptualized as follows:

VA5 | VA4 | VA3 | VA2 | VA1 | VA0

Because we know the page size (16 bytes) we can divide the VA as follows:

VA5 | VA4 |         VA3 | VA2 | VA1 | VA0
VPN                     Offset

Thus we have 2-bit VPN and 4 bit of offset.

VA:21 = | 01 | 0101 | = 5th (0101) bbyte of virtual page 01. Then we can
translate the VPN to the PPN (Physical Page Number). In the example above VPN 1
corresponds to the PPN 7 = 0b111, so VA:21 = PA:0b1110101 = 117

Page tables can get terribly large, example:

32 bit address space, with 4KB pages. This VA splits into 20-bit VPN and 12-bit
offset. A 20-bit VPN implies that there are 2^20 translations that the OS would
have to manage for each process; assuming we need 4 bytes per page-table entry
(PTE) to hold the pjhysical translation we get an immense 4MB of memory needed
for each page table. If there are 100 process, the OS would need 400 MB.

The page table has the role to store the relatives data of each page in memory,
the simplest data structure to manage a page table is the linear page table.
The os indexes the array by the vpn and looks up the PTE at that index in order
to find the desired physical page/frame number (PPN or PFN).

PTE Example:

|       PFN         |   | P | D | R | RWX | Other |

PFN -> Page Frame Number
P -> Present bit: the page could be in RAM or on the Disk (swap)
D -> Dirty bit: check if the page has been modified
R -> Reference bit: the page has been accessed (important in page replacemnt)
RWX -> Permission bit: check the permission of the page
Other -> Other

Let's take as example the following instruction:

mov eax, [21]

And examine the explicit reference to the address 21. The system must first
translate the virtual address (21) into the correct physical address (117). To
do so the system must know where the process's page table is in memory. Assume
for now that a single page-table base register contains the physical address of
the starting location of the page table. To find the location of the desired
PTE, the hardware will perform:

VirtualAddress = 21                                     // 0b010101
VPN_MASK = 0x30                                         // 0b110000
SHIFT = 4                                               // # bits in the offset
OFFSET_MASK = 15                                        // 0b001111
VPN     = (VirtualAddress & VPN_MASK) >> SHIFT          // 01 Page Number
PTEAddr = PageTableBaseRegister + (VPN * sizeof(PTE))
PTE = AccessMemory(PTEAddr)
// Check if process can access the page
if (PTE.Valid == False)
    RaiseException(SEGMENTATION_FAULT)
else if (CanAccess(PTE.ProtectBits) == False)
    RaiseException(PROTECTION_FAULT)
else
    // Access is OK: form physical address and fetch
    offset = VirtualAddress & OFFSET_MASK
    PhysAddr = (PTE.PFN << PFN_SHIFT) | offset
    Register = AccessMemory(PhysAddr)

As we can see there are lots of memory access and the page table can occupies
lots of memory, so we need to find a better solution.

--------------------------------------------------------------------------------
TLB
--------------------------------------------------------------------------------

To speed address translation, we are going to add what is called a
translation-lookaside buffer, or TLB. A TLB is part of the chip MMU, and is
simply a hardware cache of popular virtual-to-physical address translations.
Upon each virtual memory reference, the hardware first checks the TLB to see if
the desired translation is held therein; if so, the translation is performed
(quickly) without having to consult the page table (which has all translations).
Because of their tremendous performance impact, TLBs in a real sense make
virtual memory possible.

Simple TLB control flow:

VPN = (VirtualAddress & VPN_MASK) >> SHIFT
(Success, TlbEntry) = TLB_Lookup(VPN)
// TLB Hit
if (Success == True)
    if (CanAccess(TlbEntry.ProtectBits) == True)
        Offset = VirtualAddress & OFFSET_MASK
        PhysAddr = (TlbEntry.PFN << SHIFT) | Offset
        Register = AccessMemory(PhysAddr)
    else
        RaiseException(PROTECTION_FAULT)
// TLB Miss
else
    PTEAddr = PTBR + (VPN * sizeof(PTE))
    PTE = AccessMemory(PTEAddr)
    if (PTE.Valid == False)
        RaiseException(SEGMENTATION_FAULT)
    else if (CanAccess(PTE.ProtectBits) == False)
        RaiseException(PROTECTION_FAULT)
    else
        TLB_Insert(VPN, PTE.PFN, PTE.ProtectBits)
        RetryInstruction()

As we can see, if we got a tlb hit we update the register (ex. mov eax, [21]),
otherwise the hardware we'll insert inside the TLB the VPN and the
corresponding PFN, and it will retry the instruction.

> Who handle the TLB miss?

In the olden days, the hardware with CISC architecture (ex. 86) handle the TLB
miss entirely. To do this, the hardware has to know exactly where the page
tables are located in memory (using page table base register) as well as their
exact format. In the x86 there was an hardware-managed TLBs which uses a fixed
multi-level page table, where the current page table was pointer by the CR3 Reg.

More modern architectures (RISC, MIPS, etc) have a software-managed TLB. On a
TLB miss, the hardware simply raises an exception which pauses the current
instruction stream, raises the privilege level to kernel mode, and jumps to a
trap handler. The trap handler is the code with the OS that is written for the
purpose of handling TLB misses; when run, the code will lookup the translation
in the page table, and uses "privileged" instructions to update the TLB, and
return from the trap; then the hardware retries the instruction. 
The os must reserve some bytes in the TLB to handle the trap code (or it will
not fetch correctly and there could be a chain of tlb miss that never ends).
The os in this way has more flexibility to use its own data structures to
implement the page table.

> What about context switches

If we have two running process it's possible that (example) both are using the
VPN 10 and the TLB will be someting like:

-----------------------------------------
| VPN  |   PFN  |   Valid   |    Prot   |
|------|--------|-----------|-----------|
| 10   |   100  |    1      |    rw
| -    |   -    |    0      |    -
| 10   |   170  |    1      |    rx
|------|--------|-----------|-----------|

Thus, we have a problem since VPN 100 could be translated with PFN 170 or 100.

There are two possible solutions, or we flush the TLB entirely during a context
switch, or we keep and Address Space Identifier (ASID) into the TLB (similar to
the PID).

----------------------------------------------------
| VPN  |   PFN  |   Valid   |    Prot   |   ASID   |
|------|--------|-----------|-----------|----------|
| 10   |   100  |    1      |    rw     |   1
| -    |   -    |    0      |    -      |   -
| 10   |   170  |    1      |    rx     |   2
|------|--------|-----------|-----------|----------|

There is an advantage of paging, two process may share a page (ex. shrd library)

----------------------------------------------------
| VPN  |   PFN  |   Valid   |    Prot   |   ASID   |
|------|--------|-----------|-----------|----------|
| 10   |   100  |    1      |    rw     |   1
| -    |   -    |    0      |    -      |   -
| 50   |   100  |    1      |    rx     |   2 
|------|--------|-----------|-----------|----------|

--------------------------------------------------------------------------------
Paging: Smaller Tables
--------------------------------------------------------------------------------

We solved the speed problem, but we still have a size problem, with a linear
page table for each process we occupy too much space.

A naive solution is to increase the page size, for example from 4KB to 16KB.
In this way if a PTE is 4 byte, and a 18 bit VPN, we have a 1 MB per page table:
18 bit VPN = 2^18 entries * 2^2 size = 2^20 = 1 MB.
However, if we have 100 process we still use 100 MB of memory to handle the page
tables, but more importantly there could be an internal fragementation: many
space inside a page could remain unused. Thus, many system use 4KB or 8KB as
page size. The problem is also that there are lots of page unused in the PT,
example:

PFN     Valid       prot        present     dirty
--------------------------------------------------
10       1          r-x           1           0
-        0          ---           -           -
-        0          ---           -           -
-        0          ---           -           -
23       1          rw-           1           1
-        0          ---           -           -
-        0          ---           -           -
-        0          ---           -           -
-        0          ---           -           -
-        0          ---           -           -
-        0          ---           -           -
4        1          rw-           1           1

We can try to use a combination of segmentation and paging. In segmentation we
had a base register that told us where each segment lived in physical memory,
and a bound or limit register that told us the size of said segment. In our
hybrid approac we use the base not to point to the segment itself but rather to
hold the physical address of the page table of that segment, while the bound reg
is used to indicate the end of the page table. 

Example 32-bit VA with 4KB pages, and AS splitted in four segments, even if we
use only three of them.

SEG |           VPN         |       Offset      |
31  29                      11                  0

And in this case each process have 3 page table associated, during a TLB miss
the hardware uses the segment bits to determine which base/bounds to use.

SN              = (VirtualAddress & SEG_MASK) >> SN_SHIFT
VPN             = (VirtualAddress & VPN_MASK) >> VPN_SHIFT
AddressOfPTE    = Base[SN] + (VPN * sizeof(PTE))

The trick here, is that if the code segments is using its first three pages,
the code segment page table will only have three entries allocated to it and the
bounds register will be set to 3. The memory access outside the end of the seg
will generate an exception and likely lead to the termination of the process.

However this approach is not without problem:

1. If we have a large but sparsely-used heap (as usual) we can still end up with
   a lot of page table waste.
2. Page tables now can be of arbitraty size. Thus, findind free space for them
   in memory is more complicated (check how to manage free-space chapter).

Another approach is the multi-level page tables, which attacks the same problem:
how to get rid of all those invalid regions in the page table instead of keeping
them all in memory?
First chop up the page table into page-sized units; then, if an entire page of
PTE is invalid, don’t allocate that page of the page table at all. To track
whether a page of the page table is valid (and if valid, where it is in memory), 
use a new structure, called the page directory. The page directory thus either
can be used to tell you where a page of the page table is, or that the entire
page of the page table contains no valid pages.

Linear Page Table:

PTBR = 201  // Page Table Base Register

            -----------------------------
            |   prot    | valid |   PFN |
            |-----------|-------|-------|
PFN 201     |   rx      | 1     |   12  |
            |   rw      | 1     |   13  |
            |   -       | 0     |   -   |
            |   rw      | 1     |   100 |
            |-----------|-------|-------|
PFN 202     |   -       | 0     |   -   |
            |   -       | 0     |   -   |
            |   -       | 0     |   -   |
            |   -       | 0     |   -   |
            |-----------|-------|-------|
PFN 203     |   -       | 0     |   -   |
            |   -       | 0     |   -   |
            |   -       | 0     |   -   |
            |   -       | 0     |   -   |
            |-----------|-------|-------|
PFN 204     |   rx      | 1     |   103 |
            |   -       | 0     |   -   |
            |   rw      | 1     |   43  |
            |   -       | 0     |   -   |
            |---------------------------|

Multi-Level Page Table:

PDBR = 200  // Page Directory Base Register

            -----------------               -----------------------------
            | valid |   PFN |               |   prot    | valid |   PFN |
            |-------|-------|               |-----------|-------|-------|
PFN 200     | 1     |   201 ------> PFN 201 |   rx      | 1     |   12  |
            | 0     |   -   |               |   rw      | 1     |   13  |
            | 0     |   -   |               |   -       | 0     |   -   |
            | 1     |   204 ----            |   rw      | 1     |   100 |
            |---------------|  |            -----------------------------
                               |
                               |            -----------------------------
                               |            |   prot    | valid |   PFN |
                               |            |-----------|-------|--------
                               |--> PFN 204 |   rx      | 1     |   103 |
                                            |   -       | 0     |   -   |
                                            |   rw      | 1     |   43  |
                                            |   -       | 0     |   -   |
                                            -----------------------------

LoL
