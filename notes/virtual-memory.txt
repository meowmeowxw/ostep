--------------------------------------------------------------------------------
Address Space
--------------------------------------------------------------------------------

In a modern os there are multiple processes running on the system. Using
scheduling policy we can virtualize the cpu, however we need to virtualize
memory too.

Why?

For example we wants to implement protections, you don't want a process to be 
read, or worse, write some other process's memory. Another feature was the
interactivity, if you don't virtualize memory then every time the os issue a 
context switch, then the os need to save all the information of a process in a
physical memory and then run the other process. This process is very slow, so
we need to find solutions to this problem.

The abstraction of physical memory is called address space, and it is the
running program's view of memory in the system.

Example:

0KB     -------------------
            Program Code
1KB     -------------------
            Heap
2KB     -------------------
                |
                v

            Free

                ^
                |
15KB    -------------------
            Stack
16KB    -------------------

In this case the stack and heap of a program can shrink at runtime, and the
process in not loaded in physical memory 0->16KB since those addresses are
virtualized.

The goal of a virtual memory (VM) system are:

1. Transparency, the os should implement virtual memory in a way that is
   invisible to the running program.
2. Efficieny both in time and space.
3. Protection.

--------------------------------------------------------------------------------
Memory API
--------------------------------------------------------------------------------

In running a C program, there are two types of memory that are allocated. The
first is called stack memory, and allocations and deallocations of it are
managed implicitly by the compiler for you. The stack is also called automatic
memory.

Example of code:

#include <stdio.h>
#include <string.h>

void print(char *src) {
    char dst[64];
    strcpy(dst, src);
    printf("dst: %s\n", dst);
}

int main(int argc, char **argv) {
    char src[] = "hi ostep readers!";
    print(src);
	return 0;
}

disassembly of print:

opcodes         instructions

55             push rbp
4889e5         mov rbp, rsp
4883ec50       sub rsp, 0x50
48897db8       mov qword [src], rdi        ; arg1
488b55b8       mov rdx, qword [src]
488d45c0       lea rax, [dest]
4889d6         mov rsi, rdx                ; const char *src
4889c7         mov rdi, rax                ; char *dst
e8c8feffff     call sym.imp.strcpy         ;
488d45c0       lea rax, [dest]
4889c6         mov rsi, rax
488d3d8e0e00   lea rdi, str.dst
b800000000     mov eax, 0
e8c0feffff     call sym.imp.printf
90             nop
c9             leave
c3             ret

With the instructions push and pop we insert and extract instructions to/from
the stack. 
With the first three isntruction we push the precedent base pointer of the main 
function, and we "allocate" on the stack 0x50 bytes of space, so the compiler
has increased the dimension of the stack to contain our *dst.
At the end of the function the program issue a leave instruction which moves
the stack pointer to the current base pointer and then it pop the base pointer.
The last instruction is ret which pop from the stack the return address and 
set the instruction pointer to it.

Another type of memory is the heap which is created dynamically using the malloc
instruction.

int *x = (int *)malloc(sizeof(int));

With this instruction we allocate on the heap the size of an int (usually 4B).
When we don't need that space anymore we can free the space on the heap using
free:

free(x);

There are lots of bug around the heap, for example is always good practice to 
check the return value of the malloc, if the dimension requested is too large
the malloc returns NULL. Another good practice is to never reuse a variable
after it has been freed (UAF - Use After Free bugs), or never free twice the
same pointer (Double Free).

To detect potential bugs we can use a tool called valgrind.

Notes that we didn't use syscalls, but library function. At the base of the
malloc there are two syscall:

1. brk/sbrk which increase/decrease the size of the heap.
2. mmap which can create an anonymous memory region (memory not associated with
   any particular file) and that can be treated like a heap.

Never use these two syscalls to manage the heap or the program will crash
with the probability of 99.99%.

--------------------------------------------------------------------------------
Address Translation
--------------------------------------------------------------------------------

The generic technique we will use is something that is referred to as 
hardware-based address translation, or just address translation for short. With
address translation the hardware converts each memmory access changing the
virtual address provided by the instruction to a physical address where the 
desired information is actually located.

Of course, the hardware alone cannot virtualize memory, as it just provides the
low-level mechanism for doing so efficiently. The OS must get involved at key
points to set up the hardware so that the correct translations take place; it
must thus manage memory, keeping track of which locations are free and which are
in use, and judiciously intervening to maintain control over how memory is used.

As scheduling policy we need to do some assumptions to get to a final solution.
The first one is that the user's address space must be placed contiguosly in
physical memory, and that the size of the address space is less than the 
physical memory. Another assumption is that each address space is exactly the
same size.

Process 1 address space:

0KB     -------------------
            Program Code
1KB     -------------------
            Heap
2KB     -------------------
                |
                v

            Free

                ^
                |
15KB    -------------------
            Stack
16KB    -------------------


From the process perspective its address space start at 0KB and end at 16KB,
however the os wants to place the process somewhere else in physical memory not
necessarily at address 0. Example:

Physical memory:

0KB     ------------------
            OS
16KB    ------------------
            Not in Use
32KB    ------------------
            Process 1
48KB    ------------------
            Not in Use
64KB    ------------------

Thus, we want to relocate this process in memory in a way that is transparent
to the process itself.

The first idea introduced on the 1950's is referred as base and bounds, also
called dynamic relocation. Specifically we need two hardware register within
each CPU: one is called base register and the other the bounds/limit. In this
way the program is compiled as if it is loaded at address 0. However, when a 
program starts running, the os decides where in physical memory it should be
loaded and sets the base register to that value. In the above example the os
decides that the process must be relocated to address 32KB and set the base
register = 32KB. Now any memory reference is translated by the processor in the
following manner:

physical address = virtual address + base

If we have an instruction at address 300 like:

300: mov [ebx], eax

The instruction pointer (ip) or program counter (pc) is set to 300 and when
the hardware needs to fetch this instruction, it first add the value to the base
register and obtains the physical address 32KB + 300.
Before fetching the instruction the CPU will check if the memory reference is
within bounds to make sure it is legal (protection), if it's greater than the 
bounds the cpu raise an exception. The base and bounds registers are hardware
structures kept on the chip, and the process that helps the processor with 
address translation is called Memory Management Unit (MMU).

The hardware should provide special privileged (kernel) instruction to change
the base and bound registers, allowing the OS to change them when different
processes run. The os must manage the free space using some kind of data
structures (ex. free list), and when a process terminates update the data
structure. The os must save and restore the base and bounds register in for each
process (for context switch) and uses a structure called Process Control Block
(PCB). A last thing the os must handle the exception generated by the cpu,
usually it kills the process that has tried to access an invalid memory region.

--------------------------------------------------------------------------------
Segmentation
--------------------------------------------------------------------------------

Problem: there are lots of free space inside an address space of a process, for
example all the heap/stack unused.

The address space is divded between three logically-different segments: code,
stack, and heap. We can use a base and bounds pair per segment, to place each
segment indipendently in physical memory, example:

0KB     |-----------------|

        |    OS

16KB    |-----------------|
        |    Not in Use
26KB    |-----------------|
        |    Stack
28KB    |-----------------|
        |    Not in Use
32KB    |-----------------|
        |    Code
34KB    |-----------------|
        |    Heap
37KB    |-----------------|

        |    Not in Use

64KB    |-----------------|

Process address space:

0KB     |------------------|
        |    Program Code
2KB     |------------------|
        |    Unused
4KB     |------------------|
        |    Heap
7KB     |------------------|
        |        |
        |        v

        |    Free

        |        ^
        |        |
14KB    |------------------|
        |    Stack
16KB    |------------------|

Table:

Segment     Base    Size
-------------------------
Code        32K     2K
Heap        34K     3K
Stack       28K     2K

Let's suppose that we want to fetch some memory from the virtual address 4200
(heap). First we subtract from 4200 the virtual base address of the heap (4096),
so 4200-4096=104. Then we add to 104 the physical base register physical address
of the heap (34K) and we obtain the real physical address = 34920.

If we tried to refer to an illegal address as 11KB, the hardware detects that
the address is out of bounds, traps into the os, and kill the process.
SEGMENTATION FAULT ERROR.

How the hardware knows which pair of segment/offset to use to translate an
address? The technique used in the VAX/VMS system is an explicit approach, It's
uses the top bits of a virtual address to select which segments to translate.
Since we have three segments we need the top two bit.

00 -> Code
01 -> Heap
10 -> Stack
11 -> Stack

Example, if we have a 14bit virtual address, and as before we want to read the
virtual address 4200.

01          000001101000
segment     offset

01 is the heap segment and 000001101000 is the offset = 104, thus the hardware
simply takes the first two bits to determine which segment register to use and
the next 12 bits to as the offset into the segment.

Simple code:

SEG_MASK = 0x3000 = 0b11000000000000
SEG_SHIFT = 12
OFFSET_MASK = 0xfff = 0b00111111111111
Segment = (VirtualAddress & SEG_MASK) >> SEG_SHIFT
Offset = VirtualAddress & OFFSET_MASK
if (Offset >= Bounds[Segment])
    RaiseException(PROTECTION_FAULT)
else
    PhysAddr = Base[Segment] + Offset
    Register = AccessMemory(PhysAddr)

Most system to increase the address space only use one bit to decide which
segment to use and merge the heap with the code. Other systems use an implicit
approach, if an address is generated with the program counter is on the code
segment, if the address is based off of the stack/base pointer it must be on
the stack, otherwise on the heap.

The stack grows backwards (towords lower addresses), so in physical memory
it starts at 28K and grows back to 26K, while in virtual memory from 16K to 14K.
So the hardware must know which way the segment grows (a bit set to 1 if it
grows in positive direction and 0 if it grows in negative direction).

Virtual address 15KB should map to 27K in physical memory. In bit the address is
represented as: 11 1100 0000 0000. 11 designate the segment stack, and we have
an offset of 0xc00 = 3072 = 3K. In this case we substract from it the maximum
size of a segment = 4K, 3K - 4K = -1K. The base is 28K, and the physical address
is 28K - 1K = 27K.

Another important feature is the technique of code sharing to share certain
memory segments between address space. To do that the hardware needs an extra
support in the form of protections bits, for example the code segment can be
readable and executable, but not writable, while the stack can be readable and
writable.

With segmentation however we have a new problem, the size of a segment can
change (ex. using sbrk), and then the physical memory will become full of little
holes of free space, making it difficult to allocate new segments or to grow
existing ones. We call this problem external fragmentation. There are lots of 
algorithms to handle this problem like the best-fit, worst-fit, first-fit and
more complex like buddy algorithm, however no perfect solution exists for this
problem.

--------------------------------------------------------------------------------
Free-Space Management
--------------------------------------------------------------------------------

This is very hard to summarize so I will only list the characteristic of some
algorithms.
Free-Space Management is required when we have a problem of external
fragmentation, it could be the case with segmentation or the heap. In the latest
case the heap is managed by the pair of functions malloc/free.

There are several approach to manage the free space, the easiest is to use a
free list:

head -> 10 -> 30 -> 20 -> NULL

In the above example the list contains 3 free chunks, of size 10, 30, 20.

The most used algorithms on the free list are the following:

1. Best-fit: search through the free list and find chunks of free memory that
   are as big or bigger than the requested size. Then, return the one that is
   the smallest in that group of candidates;
2. Worst-fit: is the opposite of the best-fit, the scope is to leave big chunks
   free instead of losts of small chunks.
3. First-fit: simply finds the first block that is big enough and returns the
   requested amount to the user.
4. Next-fit: keep an extra pointer to the location within the list where one was
   looking last. The idea is to spread the search across all the free-list.

A more advanced method is the use of segregated list. If a particular
application has one (or a few) popular-sized request that it makes, keep a
separate list just to manage objects of that size; all other requests are
forwarded to a more general memory allocator. This is the case for the 
implementation of the glibc malloc, which uses fastbins to manage chunks with
popular size.

Link: https://sploitfun.wordpress.com/2015/02/10/understanding-glibc-malloc/

Another method is tu use a buddy allocation, the base of this allocator is to
recursively using a binary tree find enough space for the chunks requested.

--------------------------------------------------------------------------------
Paging
--------------------------------------------------------------------------------

The first approach was to choup things up into variable-sized pieces
(segmentation), thus it may be worth to consider a second approach: to chup up
space into fixed-sized pieces. We call this idea paging. We divide the address
space of a program into fixed-sized units, each of which we call a page. We view
physical memory as an array of fixed-sized slots called page frames; each of
these frames can contain a single virtual-memory page.

Example address space:

0   ---------------
        Page 0
16  ---------------
        Page 1
32  ---------------
        Page 2
48  ---------------
        Page 3
64  ---------------

Example 64 byte address space in a 128 byte physical memory:

0   -------------------
        OS
16  -------------------
        Unused
32  -------------------
        Page 3 of AS
48  -------------------
        Page 4 of AS
64  -------------------
        Unused
80  -------------------
        Page 2 of AS
96  -------------------
        Unused
112 -------------------
        Page 1 of AS
128 -------------------

In the above examples a page is 16B large and the OS can manage the free space
using a free list. To record where each virtual page of the address space is
placed in physical memory, the operating system usually keeps a per-process data
structure known as a page table. The major role of the page table is to store
address translations for each of the virtual pages of the address space, thus
letting us know where in physical memory each page resides.

Let's do an address translation of a virtual address. To translate the address
we need to split it into two components: the virtual page number (VPN) and the 
offset within the page. Because the virtual address space of the process is 64
bytes, we need 6 bits total for our virtual address (2^6 = 64). Thus our VA can
be conceptualized as follows:

VA5 | VA4 | VA3 | VA2 | VA1 | VA0

Because we know the page size (16 bytes) we can divide the VA as follows:

VA5 | VA4 |         VA3 | VA2 | VA1 | VA0
VPN                     Offset

Thus we have 2-bit VPN and 4 bit of offset.

VA:21 = | 01 | 0101 | = 5th (0101) bbyte of virtual page 01. Then we can
translate the VPN to the PPN (Physical Page Number). In the example above VPN 1
corresponds to the PPN 7 = 0b111, so VA:21 = PA:0b1110101 = 117

Page tables can get terribly large, example:

32 bit address space, with 4KB pages. This VA splits into 20-bit VPN and 12-bit
offset. A 20-bit VPN implies that there are 2^20 translations that the OS would
have to manage for each process; assuming we need 4 bytes per page-table entry
(PTE) to hold the pjhysical translation we get an immense 4MB of memory needed
for each page table. If there are 100 process, the OS would need 400 MB.

The page table has the role to store the relatives data of each page in memory,
the simplest data structure to manage a page table is the linear page table.
The os indexes the array by the vpn and looks up the PTE at that index in order
to find the desired physical page/frame number (PPN or PFN).

PTE Example:

|       PFN         |   | P | D | R | RWX | Other |

PFN -> Page Frame Number
P -> Present bit: the page could be in RAM or on the Disk (swap)
D -> Dirty bit: check if the page has been modified
R -> Reference bit: the page has been accessed (important in page replacemnt)
RWX -> Permission bit: check the permission of the page
Other -> Other

Let's take as example the following instruction:

mov eax, [21]

And examine the explicit reference to the address 21. The system must first
translate the virtual address (21) into the correct physical address (117). To
do so the system must know where the process's page table is in memory. Assume
for now that a single page-table base register contains the physical address of
the starting location of the page table. To find the location of the desired
PTE, the hardware will perform:

VirtualAddress = 21                                     // 0b010101
VPN_MASK = 0x30                                         // 0b110000
SHIFT = 4                                               // # bits in the offset
OFFSET_MASK = 15                                        // 0b001111
VPN     = (VirtualAddress & VPN_MASK) >> SHIFT          // 01 Page Number
PTEAddr = PageTableBaseRegister + (VPN * sizeof(PTE))
PTE = AccessMemory(PTEAddr)
// Check if process can access the page
if (PTE.Valid == False)
    RaiseException(SEGMENTATION_FAULT)
else if (CanAccess(PTE.ProtectBits) == False)
    RaiseException(PROTECTION_FAULT)
else
    // Access is OK: form physical address and fetch
    offset = VirtualAddress & OFFSET_MASK
    PhysAddr = (PTE.PFN << PFN_SHIFT) | offset
    Register = AccessMemory(PhysAddr)

As we can see there are lots of memory access and the page table can occupies
lots of memory, so we need to find a better solution.

--------------------------------------------------------------------------------
TLB
--------------------------------------------------------------------------------

To speed address translation, we are going to add what is called a
translation-lookaside buffer, or TLB. A TLB is part of the chip MMU, and is
simply a hardware cache of popular virtual-to-physical address translations.
Upon each virtual memory reference, the hardware first checks the TLB to see if
the desired translation is held therein; if so, the translation is performed
(quickly) without having to consult the page table (which has all translations).
Because of their tremendous performance impact, TLBs in a real sense make
virtual memory possible.

Simple TLB control flow:

VPN = (VirtualAddress & VPN_MASK) >> SHIFT
(Success, TlbEntry) = TLB_Lookup(VPN)
// TLB Hit
if (Success == True)
    if (CanAccess(TlbEntry.ProtectBits) == True)
        Offset = VirtualAddress & OFFSET_MASK
        PhysAddr = (TlbEntry.PFN << SHIFT) | Offset
        Register = AccessMemory(PhysAddr)
    else
        RaiseException(PROTECTION_FAULT)
// TLB Miss
else
    PTEAddr = PTBR + (VPN * sizeof(PTE))
    PTE = AccessMemory(PTEAddr)
    if (PTE.Valid == False)
        RaiseException(SEGMENTATION_FAULT)
    else if (CanAccess(PTE.ProtectBits) == False)
        RaiseException(PROTECTION_FAULT)
    else
        TLB_Insert(VPN, PTE.PFN, PTE.ProtectBits)
        RetryInstruction()

As we can see, if we got a tlb hit we update the register (ex. mov eax, [21]),
otherwise the hardware we'll insert inside the TLB the VPN and the
corresponding PFN, and it will retry the instruction.

> Who handle the TLB miss?

In the olden days, the hardware with CISC architecture (ex. 86) handle the TLB
miss entirely. To do this, the hardware has to know exactly where the page
tables are located in memory (using page table base register) as well as their
exact format. In the x86 there was an hardware-managed TLBs which uses a fixed
multi-level page table, where the current page table was pointer by the CR3 Reg.

More modern architectures (RISC, MIPS, etc) have a software-managed TLB. On a
TLB miss, the hardware simply raises an exception which pauses the current
instruction stream, raises the privilege level to kernel mode, and jumps to a
trap handler. The trap handler is the code with the OS that is written for the
purpose of handling TLB misses; when run, the code will lookup the translation
in the page table, and uses "privileged" instructions to update the TLB, and
return from the trap; then the hardware retries the instruction. 
The os must reserve some bytes in the TLB to handle the trap code (or it will
not fetch correctly and there could be a chain of tlb miss that never ends).
The os in this way has more flexibility to use its own data structures to
implement the page table.

> What about context switches

If we have two running process it's possible that (example) both are using the
VPN 10 and the TLB will be someting like:

-----------------------------------------
| VPN  |   PFN  |   Valid   |    Prot   |
|------|--------|-----------|-----------|
| 10   |   100  |    1      |    rw
| -    |   -    |    0      |    -
| 10   |   170  |    1      |    rx
|------|--------|-----------|-----------|

Thus, we have a problem since VPN 100 could be translated with PFN 170 or 100.

There are two possible solutions, or we flush the TLB entirely during a context
switch, or we keep and Address Space Identifier (ASID) into the TLB (similar to
the PID).

----------------------------------------------------
| VPN  |   PFN  |   Valid   |    Prot   |   ASID   |
|------|--------|-----------|-----------|----------|
| 10   |   100  |    1      |    rw     |   1
| -    |   -    |    0      |    -      |   -
| 10   |   170  |    1      |    rx     |   2
|------|--------|-----------|-----------|----------|

There is an advantage of paging, two process may share a page (ex. shrd library)

----------------------------------------------------
| VPN  |   PFN  |   Valid   |    Prot   |   ASID   |
|------|--------|-----------|-----------|----------|
| 10   |   100  |    1      |    rw     |   1
| -    |   -    |    0      |    -      |   -
| 50   |   100  |    1      |    rx     |   2 
|------|--------|-----------|-----------|----------|

--------------------------------------------------------------------------------
Paging: Smaller Tables
--------------------------------------------------------------------------------

We solved the speed problem, but we still have a size problem, with a linear
page table for each process we occupy too much space.

A naive solution is to increase the page size, for example from 4KB to 16KB.
In this way if a PTE is 4 byte, and a 18 bit VPN, we have a 1 MB per page table:
18 bit VPN = 2^18 entries * 2^2 size = 2^20 = 1 MB.
However, if we have 100 process we still use 100 MB of memory to handle the page
tables, but more importantly there could be an internal fragementation: many
space inside a page could remain unused. Thus, many system use 4KB or 8KB as
page size. The problem is also that there are lots of page unused in the PT,
example:

PFN     Valid       prot        present     dirty
--------------------------------------------------
10       1          r-x           1           0
-        0          ---           -           -
-        0          ---           -           -
-        0          ---           -           -
23       1          rw-           1           1
-        0          ---           -           -
-        0          ---           -           -
-        0          ---           -           -
-        0          ---           -           -
-        0          ---           -           -
-        0          ---           -           -
4        1          rw-           1           1

We can try to use a combination of segmentation and paging. In segmentation we
had a base register that told us where each segment lived in physical memory,
and a bound or limit register that told us the size of said segment. In our
hybrid approac we use the base not to point to the segment itself but rather to
hold the physical address of the page table of that segment, while the bound reg
is used to indicate the end of the page table. 

Example 32-bit VA with 4KB pages, and AS splitted in four segments, even if we
use only three of them.

SEG |           VPN         |       Offset      |
31  29                      11                  0

And in this case each process have 3 page table associated, during a TLB miss
the hardware uses the segment bits to determine which base/bounds to use.

SN              = (VirtualAddress & SEG_MASK) >> SN_SHIFT
VPN             = (VirtualAddress & VPN_MASK) >> VPN_SHIFT
AddressOfPTE    = Base[SN] + (VPN * sizeof(PTE))

The trick here, is that if the code segments is using its first three pages,
the code segment page table will only have three entries allocated to it and the
bounds register will be set to 3. The memory access outside the end of the seg
will generate an exception and likely lead to the termination of the process.

However this approach is not without problem:

1. If we have a large but sparsely-used heap (as usual) we can still end up with
   a lot of page table waste.
2. Page tables now can be of arbitraty size. Thus, findind free space for them
   in memory is more complicated (check how to manage free-space chapter).

Another approach is the multi-level page tables, which attacks the same problem:
how to get rid of all those invalid regions in the page table instead of keeping
them all in memory?
First chop up the page table into page-sized units; then, if an entire page of
PTE is invalid, don’t allocate that page of the page table at all. To track
whether a page of the page table is valid (and if valid, where it is in memory), 
use a new structure, called the page directory. The page directory thus either
can be used to tell you where a page of the page table is, or that the entire
page of the page table contains no valid pages.

Linear Page Table:

PTBR = 201  // Page Table Base Register

            -----------------------------
            |   prot    | valid |   PFN |
            |-----------|-------|-------|
PFN 201     |   rx      | 1     |   12  |
            |   rw      | 1     |   13  |
            |   -       | 0     |   -   |
            |   rw      | 1     |   100 |
            |-----------|-------|-------|
PFN 202     |   -       | 0     |   -   |
            |   -       | 0     |   -   |
            |   -       | 0     |   -   |
            |   -       | 0     |   -   |
            |-----------|-------|-------|
PFN 203     |   -       | 0     |   -   |
            |   -       | 0     |   -   |
            |   -       | 0     |   -   |
            |   -       | 0     |   -   |
            |-----------|-------|-------|
PFN 204     |   rx      | 1     |   103 |
            |   -       | 0     |   -   |
            |   rw      | 1     |   43  |
            |   -       | 0     |   -   |
            |---------------------------|

Multi-Level Page Table:

PDBR = 200  // Page Directory Base Register

            -----------------               -----------------------------
            | valid |   PFN |               |   prot    | valid |   PFN |
            |-------|-------|               |-----------|-------|-------|
PFN 200     | 1     |   201 ------> PFN 201 |   rx      | 1     |   12  |
            | 0     |   -   |               |   rw      | 1     |   13  |
            | 0     |   -   |               |   -       | 0     |   -   |
            | 1     |   204 ----            |   rw      | 1     |   100 |
            |---------------|  |            -----------------------------
                               |
                               |            -----------------------------
                               |            |   prot    | valid |   PFN |
                               |            |-----------|-------|--------
                               |--> PFN 204 |   rx      | 1     |   103 |
                                            |   -       | 0     |   -   |
                                            |   rw      | 1     |   43  |
                                            |   -       | 0     |   -   |
                                            -----------------------------

The page directory, is a simple two-level table, contains one entry per page of
the table. The valid bit of a PDE (Page Directory Entry) means that at least one
of the pages of the page table that the entry points to (via the PFN) is valid.

Advantages:

1. It's more compact and occupies less space
2. If carefully constructed, make the handle of free memory easier for the OS.

Disadvantages:

1. On a TLB miss, two loads from memory will be required to get the right
   translation information from the page table.
2. More complex.

Example Virtual Address 32-bit:

-----------------------------------------------------------------
|   Page Directory Index    |   Page Table Index    |   Other   |
-----------------------------------------------------------------
                Virtual Page Number                     Offset

Code to translate a virtual address:

VPN = (VirtualAddress & VPN_MASK) >> SHIFT
(Success, TlbEntry) = TLB_Lookup(VPN)
if (Success == True) // TLB Hit
    if (CanAccess(TlbEntry.ProtectBits) == True)
        Offset = VirtualAddress & OFFSET_MASK
        PhysAddr = (TlbEntry.PFN << SHIFT) | Offset
        Register = AccessMemory(PhysAddr)
    else
        RaiseException(PROTECTION_FAULT)
else // TLB Miss
    // first, get page directory entry
    PDIndex = (VPN & PD_MASK) >> PD_SHIFT
    PDEAddr = PDBR + (PDIndex * sizeof(PDE))
    PDE     = AccessMemory(PDEAddr)
    if (PDE.Valid == False)
        RaiseException(SEGMENTATION_FAULT)
    else
        // PDE is valid: now fetch PTE from page table
        PTIndex = (VPN & PT_MASK) >> PT_SHIFT
        PTEAddr = (PDE.PFN << SHIFT) + (PTIndex * sizeof(PTE))
        PTE     = AccessMemory(PTEAddr)
        if (PTE.Valid == False)
            RaiseException(SEGMENTATION_FAULT)
        else if (CanAccess(PTE.ProtectBits) == False)
            RaiseException(PROTECTION_FAULT)
        else
            TLB_Insert(VPN, PTE.PFN, PTE.ProtectBits)
            RetryInstruction()

Of course we can have more than two-levels and then we would have more page dir
index.

Another way to handle the page tables is to use a singe page table for all the 
process, and then use an hash table to lookup a particular VPN.

Thus far, we have asssumed that page tables resie in kernel-owned physical
memory, however it is possible that such page tables resides in kernel virtual
memory to allow the system to swap some of these page tables to disk.

--------------------------------------------------------------------------------
Beyond Physical Memory: Mechanisms
--------------------------------------------------------------------------------

To support larger address spaces, the os will need a place to stash away
portions of address spaces that currently aren't in great demand. In general,
such locations should have more capacity than memory (RAM), as result it's
slower, such an hard disk drive (HDD) or solide state drive (SSD).

With a larger address space we don't have to worry about the space of our
program's data structures, so the os gives the illusion to us that we have 
infinite memory (or a lot).

The first thing we will need to do is to reserve some space on the disk for
moving pages back and forth, such space is called swap space.
Thus, we will simply assume that the os can read from and write to the swap
space, in page-sized units. To do so, the OS will need to remember the disk
address of a given page. Also non-swap locations swap between HDD and RAM, for
example a program it's stored to the disk and then is loaded into the memory.

When the hardware/os looks in the PTE, it may find that the page is not present
in physical memory (RAM). The way the os determines this is through a new piece
of information in each page-table entry, known as the present bit. If the P bit
is set to 0, then the page is not in memory but rather on disk somewhere. The
act of accessing a page that is not in physical memory is called page fault.

When a page fault arise, the os runs the page-fault handler.
The OS could use the bits in the PTE normally used for data such as the PFN of
the page for a disk address. When the os receives a page fault for a page, it
looks in the PTE to find the address, and issues the request to disk to fetch
the page into memory.
When the disk I/O completes, the OS will then update the page table to mark the
page as present, update the PFN field of the PTE to record the in-memory
location of the newly-fetched page, and retry the instruction. This next attempt 
may generate a TLB miss, which would then be serviced and update the TLB with
the translation (one could alternately update the TLB when servicing the page
fault to avoid this step). Finally, a last restart would find the translation in 
the TLB and thus proceed to fetch the desired data or instruction from memory
at the translated physical address.

However the memory could be full and so we need to page out one or more pages
to make room for the new page(s) the os is about to bring in using a policy.

We can imagine that all this swap thing happen when we have the memory entirely
full, however the os must keep a small amount of memory free. If the memory
occupied is more than a certain bound then the swap daemon (a background thread)
move the pages to the disk until the occupied memory is within the bound.

--------------------------------------------------------------------------------
Beyond Physical Memory: Policies
--------------------------------------------------------------------------------

Deciding which page(s) to evict is encapsulated within the replacement policy of
the os. So we want to maximie the cache hits, in this case we consider the RAM
as a cache. Knowing the number of cache hits and misses let us calculate the
average memory access time (AMAT):

AMAT = T_m + (P_miss * T_d)

Where:
-   T_m = Cost to access memory
-   T_d = Cost to access disk
-   P_miss = Probability of not finding the data in the memory.

The optimal policy evic the page that will be accessed furthest in the future.
However, we don't know what is the page that will be accessed furthest in the
future, so we need to try something more realistic.

We can try using a FIFO, so let's suppose that we have 4 pages to access (0, 1,
2, 3). And that the 0 page is the page that need to be accessed the most.
In this case FIFO will evict the page 0 lots of the time and will do much worse
than an optimal policy.

Another policy is simply Random, so we evict pages randomly, however this
approach is unreliable and we would need a good random generator.

As with the MLFQ in the scheduler, we can try to learn from the past, to build
a new policy. If a page has been accessed many times, it clearly has some value.
In this case the page is frequently accessed and we can use a LFU (Least 
Frequently Used) policy.
Another property is that if a page was recently accessed, than it is more likely 
that it will be accessed again, and we can use a LRU (Least Recently Used)
policy.

Let's suppose that we want to use LRU as replacement policy. To do that upon
each page access, we must update some data structure to move the page in front
of the list. Another simple method would be to add to each page table the time
entry of each page as a field, so the os simply scan all the time fields in the
system to find the least-recently-used page. However as the number of page grows
, the scan complexity increase, and so we need to optimize this process.

We can approximate LRU. The idea requires some hardware support (as always), in
the form of a use bit (reference bit), which is included in the page table for
example. Whenever a page is referenced, the reference bit is set by hardware to
1. The HW never clears the bit, though; that is the responsibility of the os.
The os could use the clock algorithm:
imagine all the pages of the system arranged in a circular list. A clock hand
points to some particular page to begin with; when a replacement must occur, the
os checks if the currently-pointed to page P has the ref bit of 1 or 0. If 1,
this implies that page P was recently used and thus is not a good candidate for
replacement. Thus, the use bit for P is cleared (set to 0) and the clock hand
increments (P + 1). The algorithm continues until it finds a use bit that is set
to 0.

Another consideration of the clock algorithm is whether a page has been modified
or not while in memory. If a page has been modified and is thus dirty, it must
be written back to disk to evict it, which is expensive. To support this
behavior the hardware should include a modified bit (dirty bit) which is set
any time a page is written, and thus can be incorporated into the page-replacemt
algorithm.

When a computer's virtual memory resources are overused, the system will
constantly be paging, this condition is called thrashing. In the early Linux
version when memory is oversubscribed, the kernel run an out-of-memory killer
which chooses a memory-intensive process and kills it, thus reducing memory 
overhead (very dangerous approach).

--------------------------------------------------------------------------------
Complete Virtual Memory System
--------------------------------------------------------------------------------

We will study how the Linux VM works for Intel x86. Much like other modern os,
a linux virtual address space consists of a user portion (program code,stack,
heap) and a kernel portion (where kernel code, stacks, heap, and other parts
reside). 

0x00000000  ----------------------  |  
                Page 0: Invalid     |
            ----------------------  |  
            ----------------------  |  
                User Code           |
            ----------------------  |  
                User Heap           |
            ----------------------  |  
                    |               |
                    |               |
                    v               |       User
                                    |
                                    |
                    ^               |
                    |               |
                    |               |
            ----------------------  |  
                User Stack          |
            ----------------------  |  
0xC0000000  ------------------------|-----------------
                Kernel (Logical)    |
            ----------------------  | 
                Kernel (virtual)    |       Kernel
            ----------------------  |  
            ----------------------  |  

The kernel portion is the same across processes, while the user portion changes
with context switches. One slighlty interesting aspect of Linux is that it
contains two types of kernel virtual addresses.
The first are known as kernel logical addresses. This is what you would consider
the normal virtual address space of the kernel; to get more memory of this type,
kernel code needs to call kmalloc. Most kernel data structures live here,
page-table, PCB, per-process kernel stacks, and so forth.
This addresses are directly mapped to the physical memory:
-   0xC0000000 -> 0x00000000
-   0xC0000FFF -> 0x00000FFF, and so forth.

The other type of kernel address is kernel virtual address. To get memory of
this type, kernel code calls a different allocator, vmalloc, which return a
pointer to a virtually contigues region of the desirezed size. The reason of
this memory, is that it enables the kernel to address more than 1 GB of memory.

x86 use a multi-level page table, however x86-64 use a four-level table,
however the full 64-bit nture of the VA space is not yet used, but only the
bottom 48 bit :

63      47          31          15          0
| Unused |  P1 |    P2 |   P3 | P4 | Offset |

The bottom 12 bits (4 KB page size) are used as the offset, while the middle
36 bits of VA are used for the translation.

Some classical feature of the VM is that:

1. VA 0 is used to catch null pointer
2. A technique called COW Copy On Write, which is implemented almost everywhere.
   When the OS needs to copy a page from one address space to another, instead
   of copying it, it can map it into the target address space and mark it
   read-only in both address spaces. If both address spaces only read the page,
   no further action is taken, and thus the OS has realized a fast copy without
   actually moving any data.
   If, however, one of the address spaces does indeed try to write to the page,
   it will trap into the OS. The OS will then notice that the page is a COW
   page, and thus (lazily) allocate a new page, fill it with the data, and map
   this new page into the address space of the faulting process. The process
   then continues and now has its own private copy of the page. This is useful
   for example when calling fork() or the combination fork()/exec().

